{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561de4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# file: playwright_runner.py\n",
    "# Shopify Channel Performance (weekly) -> Summary -> Google Sheets\n",
    "# ===============================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# --- Windows stability for Playwright\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "# --- deps (install if missing)\n",
    "def ensure(pkg: str):\n",
    "    import importlib\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        import subprocess\n",
    "        print(f\"{pkg} not found; installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "ensure(\"python-dotenv\")\n",
    "ensure(\"playwright\")\n",
    "ensure(\"pandas\")\n",
    "ensure(\"google-api-python-client\")\n",
    "ensure(\"google-auth\")\n",
    "ensure(\"google-auth-oauthlib\")\n",
    "ensure(\"google-auth-httplib2\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, TimeoutError as PWTimeoutError\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# Ensure Playwright Chromium exists (idempotent)\n",
    "def ensure_playwright_browsers():\n",
    "    import subprocess\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"])\n",
    "    except Exception as e:\n",
    "        print('Failed to install Playwright Chromium automatically:', e)\n",
    "        print('Run manually: python -m playwright install chromium')\n",
    "\n",
    "ensure_playwright_browsers()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -------------------------\n",
    "# Date helpers\n",
    "# -------------------------\n",
    "def parse_ymd(s: str) -> date:\n",
    "    return datetime.strptime(s, \"%Y-%m-%d\").date()\n",
    "\n",
    "def ymd(d: date) -> str:\n",
    "    return d.isoformat()\n",
    "\n",
    "def week_start_for(d: date, week_start: int = 0) -> date:\n",
    "    # week_start: Mon=0 ... Sun=6\n",
    "    delta = (d.weekday() - week_start) % 7\n",
    "    return d - timedelta(days=delta)\n",
    "\n",
    "def iter_weeks(since: date, until: date, week_start: int = 0):\n",
    "    \"\"\"\n",
    "    Yields inclusive (start,end) ranges aligned to week_start,\n",
    "    but clipped to SINCE/UNTIL.\n",
    "    \"\"\"\n",
    "    cur = since\n",
    "    while cur <= until:\n",
    "        anchor = week_start_for(cur, week_start)\n",
    "        week_end = anchor + timedelta(days=6)\n",
    "        end = min(week_end, until)\n",
    "        yield cur, end\n",
    "        cur = end + timedelta(days=1)\n",
    "\n",
    "def format_date_range(start_ymd: str, end_ymd: str) -> str:\n",
    "    sdt = datetime.strptime(start_ymd, \"%Y-%m-%d\")\n",
    "    edt = datetime.strptime(end_ymd, \"%Y-%m-%d\")\n",
    "    return f\"{sdt.month}/{sdt.day}-{edt.month}/{edt.day}\"\n",
    "\n",
    "# -------------------------\n",
    "# Args + env config\n",
    "# -------------------------\n",
    "def get_date_range_from_args_or_env():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--since\", type=str, default=None)\n",
    "    parser.add_argument(\"--until\", type=str, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    since = args.since or os.getenv(\"SINCE\") or \"2025-09-01\"\n",
    "    until = args.until or os.getenv(\"UNTIL\") or ymd(today)\n",
    "    return since, until\n",
    "\n",
    "STORE_SLUG = os.getenv(\"SHOPIFY_STORE_SLUG\")\n",
    "SHOPIFY_EMAIL = os.getenv(\"SHOPIFY_EMAIL\")\n",
    "SHOPIFY_PASSWORD = os.getenv(\"SHOPIFY_PASSWORD\")\n",
    "AUTO_LOGIN = os.getenv(\"AUTO_LOGIN\", \"0\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "DOWNLOAD_DIR = Path(os.getenv(\"DOWNLOAD_DIR\", \"./downloads\")).resolve()\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SINCE, UNTIL = get_date_range_from_args_or_env()\n",
    "COUNTRY = os.getenv(\"COUNTRY\", \"US\")\n",
    "\n",
    "HEADLESS = os.getenv(\"CHROME_HEADLESS\", \"0\").lower() not in (\"0\", \"false\", \"no\")\n",
    "STATE_FILE = Path(os.getenv(\"PLAYWRIGHT_STATE_FILE\", \"playwright_storage_state.json\")).resolve()\n",
    "\n",
    "UPLOAD_TO_SHEET = os.getenv(\"UPLOAD_TO_SHEET\", \"0\").lower() in (\"1\", \"true\", \"yes\")\n",
    "SHEET_ID = os.getenv(\"SHEET_ID\")\n",
    "SHEET_NAME = os.getenv(\"SHEET_NAME\", \"summary_df\")\n",
    "SHEET_MODE = os.getenv(\"SHEET_MODE\", \"append\").strip().lower()  # append | overwrite\n",
    "\n",
    "# Week starts Monday by default\n",
    "WEEK_START = int(os.getenv(\"WEEK_START\", \"0\"))\n",
    "\n",
    "CREDENTIALS_JSON = Path(os.getenv(\"GOOGLE_CREDENTIALS_JSON\", \"credentials.json\")).resolve()\n",
    "TOKEN_JSON = Path(os.getenv(\"GOOGLE_TOKEN_JSON\", \"token.json\")).resolve()\n",
    "\n",
    "# -------------------------\n",
    "# Google Sheets helpers (OAuth installed app)\n",
    "# -------------------------\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "\n",
    "def get_sheets_service():\n",
    "    creds = None\n",
    "    if TOKEN_JSON.exists():\n",
    "        creds = Credentials.from_authorized_user_file(str(TOKEN_JSON), SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            if not CREDENTIALS_JSON.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Missing {CREDENTIALS_JSON}. Save your OAuth JSON as 'credentials.json' next to this script.\"\n",
    "                )\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_JSON), SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        TOKEN_JSON.write_text(creds.to_json(), encoding=\"utf-8\")\n",
    "\n",
    "    return build(\"sheets\", \"v4\", credentials=creds)\n",
    "\n",
    "def ensure_tab(service, spreadsheet_id: str, sheet_name: str):\n",
    "    meta = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()\n",
    "    existing = [s[\"properties\"][\"title\"] for s in meta.get(\"sheets\", [])]\n",
    "    if sheet_name in existing:\n",
    "        return\n",
    "    req = {\"requests\": [{\"addSheet\": {\"properties\": {\"title\": sheet_name}}}]}\n",
    "    service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body=req).execute()\n",
    "\n",
    "def upload_df_to_sheet(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str, mode: str = \"append\"):\n",
    "    if not spreadsheet_id:\n",
    "        raise ValueError(\"SHEET_ID missing in .env\")\n",
    "\n",
    "    service = get_sheets_service()\n",
    "    ensure_tab(service, spreadsheet_id, sheet_name)\n",
    "\n",
    "    header_and_rows = [df.columns.tolist()] + df.astype(object).where(pd.notnull(df), \"\").values.tolist()\n",
    "\n",
    "    if mode == \"overwrite\":\n",
    "        service.spreadsheets().values().clear(\n",
    "            spreadsheetId=spreadsheet_id, range=f\"{sheet_name}!A:ZZ\", body={}\n",
    "        ).execute()\n",
    "        service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            body={\"values\": header_and_rows},\n",
    "        ).execute()\n",
    "        print(f\"✅ Uploaded (overwrite) to tab '{sheet_name}'\")\n",
    "        return\n",
    "\n",
    "    # append\n",
    "    first_cell = service.spreadsheets().values().get(\n",
    "        spreadsheetId=spreadsheet_id, range=f\"{sheet_name}!A1:A1\"\n",
    "    ).execute().get(\"values\", [])\n",
    "\n",
    "    if not first_cell:\n",
    "        # empty sheet => include header\n",
    "        service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            body={\"values\": header_and_rows},\n",
    "        ).execute()\n",
    "        print(f\"✅ Uploaded (new tab) to '{sheet_name}'\")\n",
    "    else:\n",
    "        # existing header => append only values\n",
    "        service.spreadsheets().values().append(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body={\"values\": df.astype(object).where(pd.notnull(df), \"\").values.tolist()},\n",
    "        ).execute()\n",
    "        print(f\"✅ Appended {len(df)} row(s) to '{sheet_name}'\")\n",
    "\n",
    "# -------------------------\n",
    "# Summarization logic\n",
    "# -------------------------\n",
    "def to_number(x) -> float:\n",
    "    if x is None:\n",
    "        return 0.0\n",
    "    s = str(x).strip()\n",
    "    if s in (\"\", \"—\", \"-\", \"nan\", \"None\"):\n",
    "        return 0.0\n",
    "    s = s.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def bucket_row(ref_platform: str, channel: str, typ: str) -> str:\n",
    "    rp = (ref_platform or \"\").strip().lower()\n",
    "    ch = (channel or \"\").strip().lower()\n",
    "    ty = (typ or \"\").strip().lower()\n",
    "\n",
    "    if ch == \"direct\" or rp == \"direct\":\n",
    "        return \"Direct Website Sales (Organic)\"\n",
    "    if ch == \"google\" and ty == \"paid\":\n",
    "        return \"Google ads (Sales)\"\n",
    "    if ch == \"google\" and ty == \"organic\":\n",
    "        return \"Google Search (Organic Sales)\"\n",
    "    if ch == \"attentive\" or rp == \"attentive\":\n",
    "        return \"Attentive SMS (Sales)\"\n",
    "    if ch == \"privy\" or rp == \"privy\":\n",
    "        return \"Privey Email Marketing (Sales)\"\n",
    "\n",
    "    # ✅ ActiveCampaign separate\n",
    "    if ch == \"activecampaign\" or rp == \"activecampaign\":\n",
    "        return \"ActiveCampaign (Sales)\"\n",
    "\n",
    "    return \"Other Channel Sales MISC\"\n",
    "\n",
    "def build_misc_notes(df_other: pd.DataFrame, ch_col: str, ty_col: str) -> str:\n",
    "    if df_other.empty:\n",
    "        return \"\"\n",
    "    tmp = df_other.copy()\n",
    "    tmp[\"_name\"] = tmp.apply(lambda r: f\"{str(r[ch_col]).strip()} ({str(r[ty_col]).strip()})\", axis=1)\n",
    "    grouped = (\n",
    "        tmp.groupby(\"_name\", as_index=False)[\"_sales\"].sum()\n",
    "        .sort_values(\"_sales\", ascending=False)\n",
    "    )\n",
    "    parts = []\n",
    "    for _, r in grouped.head(12).iterrows():\n",
    "        if float(r[\"_sales\"]) > 0:\n",
    "            parts.append(f\"{r['_name']} ${float(r['_sales']):,.2f}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "def summarize_channel_csv_to_weekly_row(csv_path: Path, start: date, end: date) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # ✅ remove fully blank rows\n",
    "    df = df.dropna(how=\"all\")\n",
    "    df = df[(df.astype(str).apply(lambda x: x.str.strip()).ne(\"\").any(axis=1))]\n",
    "\n",
    "    colmap = {c.lower().strip(): c for c in df.columns}\n",
    "    def col(name_lower):\n",
    "        return colmap.get(name_lower, None)\n",
    "\n",
    "    rp_col = col(\"referring platform\")\n",
    "    ch_col = col(\"channel\")\n",
    "    ty_col = col(\"type\")\n",
    "    sales_col = col(\"sales\")\n",
    "    cost_col = col(\"cost\")\n",
    "\n",
    "    if not (rp_col and ch_col and ty_col and sales_col):\n",
    "        raise ValueError(f\"CSV missing required columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    df[\"_sales\"] = df[sales_col].apply(to_number)\n",
    "    df[\"_cost\"] = df[cost_col].apply(to_number) if cost_col else 0.0\n",
    "\n",
    "    df[\"_bucket\"] = df.apply(lambda r: bucket_row(r[rp_col], r[ch_col], r[ty_col]), axis=1)\n",
    "\n",
    "    agg = df.groupby(\"_bucket\", as_index=False).agg({\"_sales\": \"sum\", \"_cost\": \"sum\"})\n",
    "    sales_by = {row[\"_bucket\"]: float(row[\"_sales\"]) for _, row in agg.iterrows()}\n",
    "    cost_by  = {row[\"_bucket\"]: float(row[\"_cost\"])  for _, row in agg.iterrows()}\n",
    "\n",
    "    other_df = df[df[\"_bucket\"] == \"Other Channel Sales MISC\"].copy()\n",
    "    misc_notes = build_misc_notes(other_df, ch_col, ty_col)\n",
    "\n",
    "    tot_sales = float(df[\"_sales\"].sum())\n",
    "    tot_cost  = float(df[\"_cost\"].sum())\n",
    "    gpm = ((tot_sales - tot_cost) / tot_sales) if tot_sales else 0.0\n",
    "\n",
    "    start_str = start.isoformat()\n",
    "    end_str = end.isoformat()\n",
    "\n",
    "    row = {\n",
    "        \"Month\": start.strftime(\"%B\"),\n",
    "        \"Dates/ Week\": format_date_range(start_str, end_str),\n",
    "\n",
    "        \"Direct Website Sales (Organic)\": round(sales_by.get(\"Direct Website Sales (Organic)\", 0.0), 2),\n",
    "        \"Google ads (Sales)\": round(sales_by.get(\"Google ads (Sales)\", 0.0), 2),\n",
    "        \"Google Search (Organic Sales)\": round(sales_by.get(\"Google Search (Organic Sales)\", 0.0), 2),\n",
    "        \"Attentive SMS (Sales)\": round(sales_by.get(\"Attentive SMS (Sales)\", 0.0), 2),\n",
    "        \"Privey Email Marketing (Sales)\": round(sales_by.get(\"Privey Email Marketing (Sales)\", 0.0), 2),\n",
    "        \"ActiveCampaign (Sales)\": round(sales_by.get(\"ActiveCampaign (Sales)\", 0.0), 2),\n",
    "        \"Other Channel Sales MISC\": round(sales_by.get(\"Other Channel Sales MISC\", 0.0), 2),\n",
    "\n",
    "        \"Tot Sales\": round(tot_sales, 2),\n",
    "\n",
    "        \"Google ads (Cost)\": round(cost_by.get(\"Google ads (Sales)\", 0.0), 2),\n",
    "        \"Privey Email Marketing (Cost)\": round(cost_by.get(\"Privey Email Marketing (Sales)\", 0.0), 2),\n",
    "        \"Attentive SMS (Cost)\": round(cost_by.get(\"Attentive SMS (Sales)\", 0.0), 2),\n",
    "        \"Total Cost\": round(tot_cost, 2),\n",
    "\n",
    "        \"GPM\": round(gpm, 4),\n",
    "        \"MISC.\": misc_notes,\n",
    "\n",
    "        # \"Upload_Date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"Range_Start\": start_str,\n",
    "        \"Range_End\": end_str,\n",
    "        \"Country\": COUNTRY,\n",
    "    }\n",
    "\n",
    "    ordered_cols = [\n",
    "        \"Month\",\n",
    "        \"Dates/ Week\",\n",
    "        \"Direct Website Sales (Organic)\",\n",
    "        \"Google ads (Sales)\",\n",
    "        \"Google Search (Organic Sales)\",\n",
    "        \"Attentive SMS (Sales)\",\n",
    "        \"Privey Email Marketing (Sales)\",\n",
    "        \"ActiveCampaign (Sales)\",\n",
    "        \"Other Channel Sales MISC\",\n",
    "        \"Tot Sales\",\n",
    "        \"Google ads (Cost)\",\n",
    "        \"Privey Email Marketing (Cost)\",\n",
    "        \"Attentive SMS (Cost)\",\n",
    "        \"Total Cost\",\n",
    "        \"GPM\",\n",
    "        \"MISC.\",\n",
    "        # \"Upload_Date\",\n",
    "        \"Range_Start\",\n",
    "        \"Range_End\",\n",
    "        \"Country\",\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame([[row.get(c, \"\") for c in ordered_cols]], columns=ordered_cols)\n",
    "\n",
    "# -------------------------\n",
    "# Shopify automation helpers\n",
    "# -------------------------\n",
    "def build_report_url(store_slug: str, since_ymd: str, until_ymd: str, country: str) -> str:\n",
    "    return (\n",
    "        f\"https://admin.shopify.com/store/{store_slug}/marketing/reports/channels\"\n",
    "        f\"?attributionModel=last_click_non_direct\"\n",
    "        f\"&since={since_ymd}&until={until_ymd}\"\n",
    "        f\"&sortColumn=sessions&sortDirection=desc\"\n",
    "        f\"&country={country}\"\n",
    "    )\n",
    "\n",
    "async def auto_login_shopify(page):\n",
    "    if not SHOPIFY_EMAIL or not SHOPIFY_PASSWORD:\n",
    "        raise ValueError(\"AUTO_LOGIN=1 but SHOPIFY_EMAIL/SHOPIFY_PASSWORD missing in .env\")\n",
    "\n",
    "    await page.goto(f\"https://admin.shopify.com/store/{STORE_SLUG}\", timeout=60000)\n",
    "    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "\n",
    "    # Email\n",
    "    try:\n",
    "        await page.fill(\"#account_email\", SHOPIFY_EMAIL, timeout=15000)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Password\n",
    "    try:\n",
    "        await page.fill(\"#account_password\", SHOPIFY_PASSWORD, timeout=15000)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2FA if present\n",
    "    try:\n",
    "        otp_selector = \"input[name='two_factor_code'], input[name='otp']\"\n",
    "        await page.wait_for_selector(otp_selector, timeout=8000)\n",
    "        otp = os.getenv(\"SHOPIFY_OTP\", \"\").strip() or input(\"Enter Shopify 2FA code: \").strip()\n",
    "        await page.fill(otp_selector, otp)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    await page.wait_for_selector(\"nav[aria-label='Primary'], #AppFrameMain\", timeout=60000)\n",
    "\n",
    "async def click_export_flow(page):\n",
    "    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "    await page.wait_for_selector(\"button\", timeout=60000)\n",
    "    await page.wait_for_timeout(1000)\n",
    "\n",
    "    export_clicked = False\n",
    "    for sel in [\n",
    "        \"button:has-text('Export')\",\n",
    "        \"button[aria-label='Export']\",\n",
    "        \"[role='button']:has-text('Export')\",\n",
    "    ]:\n",
    "        try:\n",
    "            await page.click(sel, timeout=6000)\n",
    "            export_clicked = True\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not export_clicked:\n",
    "        for sel in [\n",
    "            \"button[aria-label='More actions']\",\n",
    "            \"button[aria-haspopup='menu']\",\n",
    "        ]:\n",
    "            try:\n",
    "                await page.click(sel, timeout=6000)\n",
    "                break\n",
    "            except Exception:\n",
    "                pass\n",
    "        await page.click(\"text=Export\", timeout=15000)\n",
    "\n",
    "    await page.wait_for_timeout(800)\n",
    "\n",
    "    # Try choose CSV if offered\n",
    "    for sel in [\"text=CSV\", \"button:has-text('CSV')\", \"[role='menuitem']:has-text('CSV')\", \"label:has-text('CSV')\"]:\n",
    "        try:\n",
    "            await page.click(sel, timeout=2500)\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Confirm export\n",
    "    for sel in [\"button:has-text('Export')\", \"button[aria-label='Export']\", \"text=Export\"]:\n",
    "        try:\n",
    "            await page.click(sel, timeout=8000)\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "async def run():\n",
    "    if not STORE_SLUG:\n",
    "        raise ValueError(\"Missing SHOPIFY_STORE_SLUG in .env\")\n",
    "\n",
    "    since_d = parse_ymd(SINCE)\n",
    "    until_d = parse_ymd(UNTIL)\n",
    "    if until_d < since_d:\n",
    "        raise ValueError(\"UNTIL must be >= SINCE\")\n",
    "\n",
    "    print(f\"DOWNLOAD_DIR: {DOWNLOAD_DIR}\")\n",
    "    print(f\"Range: {since_d} -> {until_d} (inclusive)\")\n",
    "    print(f\"SHEET_NAME: {SHEET_NAME} | MODE: {SHEET_MODE} | UPLOAD_TO_SHEET: {UPLOAD_TO_SHEET}\")\n",
    "\n",
    "    overwrite_first = (SHEET_MODE == \"overwrite\")\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=HEADLESS,\n",
    "            args=[\"--disable-dev-shm-usage\", \"--no-sandbox\", \"--disable-setuid-sandbox\"]\n",
    "        )\n",
    "\n",
    "        if STATE_FILE.exists():\n",
    "            context = await browser.new_context(storage_state=str(STATE_FILE), accept_downloads=True)\n",
    "            print(f\"Loaded storage state from {STATE_FILE}\")\n",
    "        else:\n",
    "            context = await browser.new_context(accept_downloads=True)\n",
    "\n",
    "        page = await context.new_page()\n",
    "\n",
    "        try:\n",
    "            await page.goto(f\"https://admin.shopify.com/store/{STORE_SLUG}\", timeout=60000)\n",
    "\n",
    "            if not STATE_FILE.exists():\n",
    "                if AUTO_LOGIN:\n",
    "                    print(\"AUTO_LOGIN enabled: attempting login...\")\n",
    "                    await auto_login_shopify(page)\n",
    "                else:\n",
    "                    print(\"\\nFIRST RUN: Please log in to Shopify in the opened browser, then press Enter here.\\n\")\n",
    "                    input(\"Press Enter after Shopify login is complete... \")\n",
    "\n",
    "                await context.storage_state(path=str(STATE_FILE))\n",
    "                print(f\"✅ Saved Shopify session to: {STATE_FILE}\")\n",
    "\n",
    "            all_summary_rows = []\n",
    "\n",
    "            for start, end in iter_weeks(since_d, until_d, week_start=WEEK_START):\n",
    "                since_ymd = ymd(start)\n",
    "                until_ymd = ymd(end)\n",
    "                report_url = build_report_url(STORE_SLUG, since_ymd, until_ymd, COUNTRY)\n",
    "\n",
    "                print(f\"\\n--- Exporting week {since_ymd} to {until_ymd} ---\")\n",
    "                await page.goto(report_url, timeout=60000)\n",
    "\n",
    "                async with page.expect_download(timeout=180000) as dl_info:\n",
    "                    await click_export_flow(page)\n",
    "\n",
    "                download = await dl_info.value\n",
    "                stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                raw_path = DOWNLOAD_DIR / f\"shopify_channel_perf_{COUNTRY}_{since_ymd}_{until_ymd}_{stamp}.csv\"\n",
    "                await download.save_as(str(raw_path))\n",
    "                print(f\"✅ Downloaded raw: {raw_path}\")\n",
    "\n",
    "                summary_df = summarize_channel_csv_to_weekly_row(raw_path, start, end)\n",
    "                print(\"SUMMARY ROW PREVIEW:\")\n",
    "                print(summary_df.to_string(index=False))\n",
    "\n",
    "                summary_path = raw_path.with_name(raw_path.stem + \"_SUMMARY.csv\")\n",
    "                summary_df.to_csv(summary_path, index=False)\n",
    "                print(f\"✅ Saved summary: {summary_path}\")\n",
    "\n",
    "                all_summary_rows.append(summary_df)\n",
    "\n",
    "                if UPLOAD_TO_SHEET:\n",
    "                    mode = \"overwrite\" if overwrite_first else \"append\"\n",
    "                    upload_df_to_sheet(summary_df, SHEET_ID, SHEET_NAME, mode=mode)\n",
    "                    print(f\"✅ Uploaded summary row to spreadsheet {SHEET_ID} tab '{SHEET_NAME}' (mode={mode})\")\n",
    "                    overwrite_first = False\n",
    "\n",
    "            if all_summary_rows:\n",
    "                combined = pd.concat(all_summary_rows, ignore_index=True)\n",
    "                combined_path = DOWNLOAD_DIR / f\"shopify_weekly_summary_{COUNTRY}_{SINCE}_{UNTIL}_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                combined.to_csv(combined_path, index=False)\n",
    "                print(f\"\\n✅ Combined summary saved: {combined_path}\")\n",
    "\n",
    "        finally:\n",
    "            await context.close()\n",
    "            await browser.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
