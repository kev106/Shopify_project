{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887bc5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python-dotenv not found; installing...\n",
      "google-api-python-client not found; installing...\n",
      "google-auth not found; installing...\n",
      "google-auth-oauthlib not found; installing...\n",
      "google-auth-httplib2 not found; installing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# file: playwright_runner.py\n",
    "# Weekly Shopify Channel Performance -> Summary -> Google Sheets\n",
    "# - Dynamic SINCE/UNTIL via CLI args or .env (defaults UNTIL=today)\n",
    "# - Optional AUTO_LOGIN using SHOPIFY_EMAIL/SHOPIFY_PASSWORD (+ optional 2FA)\n",
    "# - First successful login saves session to playwright_storage_state.json for future runs\n",
    "# ===============================================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# --- Windows stability: required for Playwright subprocess in some notebook/event-loop setups\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "\n",
    "# --- deps (auto-install if missing)\n",
    "def ensure(pkg: str):\n",
    "    import importlib\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        import subprocess\n",
    "        print(f\"{pkg} not found; installing...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "ensure(\"python-dotenv\")\n",
    "ensure(\"playwright\")\n",
    "ensure(\"pandas\")\n",
    "ensure(\"google-api-python-client\")\n",
    "ensure(\"google-auth\")\n",
    "ensure(\"google-auth-oauthlib\")\n",
    "ensure(\"google-auth-httplib2\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, TimeoutError as PWTimeoutError\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "# Ensure browser binaries exist (idempotent)\n",
    "def ensure_playwright_browsers():\n",
    "    import subprocess\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"playwright\", \"install\", \"chromium\"])\n",
    "    except Exception as e:\n",
    "        print('Failed to install Playwright Chromium automatically:', e)\n",
    "        print('Run manually: python -m playwright install chromium')\n",
    "\n",
    "ensure_playwright_browsers()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers: parsing args + date logic\n",
    "# -------------------------\n",
    "def parse_ymd(s: str) -> date:\n",
    "    return datetime.strptime(s, \"%Y-%m-%d\").date()\n",
    "\n",
    "def ymd(d: date) -> str:\n",
    "    return d.isoformat()\n",
    "\n",
    "def get_date_range_from_args_or_env():\n",
    "    \"\"\"\n",
    "    Precedence:\n",
    "      1) CLI args --since/--until\n",
    "      2) .env SINCE/UNTIL\n",
    "      3) fallback SINCE=\"2025-09-01\", UNTIL=today\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(add_help=True)\n",
    "    parser.add_argument(\"--since\", type=str, default=None, help=\"YYYY-MM-DD (inclusive)\")\n",
    "    parser.add_argument(\"--until\", type=str, default=None, help=\"YYYY-MM-DD (inclusive)\")\n",
    "    parser.add_argument(\"--last-days\", type=int, default=None, help=\"Override since/until: last N days ending today (inclusive)\")\n",
    "    parser.add_argument(\"--last-full-week\", action=\"store_true\", help=\"Override since/until: last full Mon-Sun week\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    today = datetime.now().date()\n",
    "\n",
    "    if args.last_days and args.last_days > 0:\n",
    "        since_d = today - timedelta(days=args.last_days - 1)\n",
    "        until_d = today\n",
    "        return ymd(since_d), ymd(until_d)\n",
    "\n",
    "    if args.last_full_week:\n",
    "        # last full week Mon-Sun ending before today (if today is Sun, last week is previous Mon-Sun)\n",
    "        # Define week start Monday=0\n",
    "        week_start = 0\n",
    "        # Find most recent Sunday before today\n",
    "        # weekday: Mon=0 ... Sun=6\n",
    "        days_since_sun = (today.weekday() - 6) % 7\n",
    "        last_sun = today - timedelta(days=days_since_sun or 7)  # if today is Sunday, go back 7 days\n",
    "        last_mon = last_sun - timedelta(days=6)\n",
    "        return ymd(last_mon), ymd(last_sun)\n",
    "\n",
    "    since = args.since or os.getenv(\"SINCE\") or \"2025-09-01\"\n",
    "    until = args.until or os.getenv(\"UNTIL\") or ymd(today)\n",
    "    return since, until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------\n",
    "# Config from .env\n",
    "#------------------\n",
    "\n",
    "STORE_SLUG = os.getenv(\"SHOPIFY_STORE_SLUG\")\n",
    "DOWNLOAD_DIR = Path(os.getenv(\"DOWNLOAD_DIR\", \"./downloads\")).resolve()\n",
    "DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SINCE, UNTIL = get_date_range_from_args_or_env()\n",
    "COUNTRY = os.getenv(\"COUNTRY\", \"US\")\n",
    "\n",
    "# Visible browser for first run recommended\n",
    "HEADLESS = os.getenv(\"CHROME_HEADLESS\", \"0\").lower() not in (\"0\", \"false\", \"no\")\n",
    "\n",
    "STATE_FILE = Path(os.getenv(\"PLAYWRIGHT_STATE_FILE\", \"playwright_storage_state.json\")).resolve()\n",
    "\n",
    "UPLOAD_TO_SHEET = os.getenv(\"UPLOAD_TO_SHEET\", \"0\").lower() in (\"1\", \"true\", \"yes\")\n",
    "SHEET_ID = os.getenv(\"SHEET_ID\")\n",
    "SHEET_NAME = os.getenv(\"SHEET_NAME\", \"Automated_reports_updated\")\n",
    "SHEET_MODE = os.getenv(\"SHEET_MODE\", \"append\").lower()  # append | overwrite\n",
    "\n",
    "CREDENTIALS_JSON = Path(os.getenv(\"GOOGLE_CREDENTIALS_JSON\", \"credentials.json\")).resolve()\n",
    "TOKEN_JSON = Path(os.getenv(\"GOOGLE_TOKEN_JSON\", \"token.json\")).resolve()\n",
    "\n",
    "# Weekly loop settings:\n",
    "# WEEK_START = 0 means Monday, 6 means Sunday\n",
    "WEEK_START = int(os.getenv(\"WEEK_START\", \"0\"))\n",
    "\n",
    "# Optional: custom labels per week\n",
    "# WEEK_LABELS format: \"YYYY-MM-DD:YYYY-MM-DD=Label;YYYY-MM-DD:YYYY-MM-DD=Label2\"\n",
    "WEEK_LABELS_RAW = os.getenv(\"WEEK_LABELS\", \"\").strip()\n",
    "\n",
    "# Optional: auto login to Shopify\n",
    "AUTO_LOGIN = os.getenv(\"AUTO_LOGIN\", \"0\").lower() in (\"1\", \"true\", \"yes\")\n",
    "SHOPIFY_EMAIL = os.getenv(\"SHOPIFY_EMAIL\")\n",
    "SHOPIFY_PASSWORD = os.getenv(\"SHOPIFY_PASSWORD\")\n",
    "\n",
    "# REPORT_URL = (\n",
    "#     f\"https://admin.shopify.com/store/{STORE_SLUG}/marketing/reports/channels\"\n",
    "#     f\"?attributionModel=last_click_non_direct\"\n",
    "#     f\"&since={SINCE}&until={UNTIL}\"\n",
    "#     f\"&sortColumn=sessions&sortDirection=desc\"\n",
    "#     f\"&country={COUNTRY}\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b72676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Google Sheets OAuth helpers\n",
    "#----------------------------\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "\n",
    "def get_sheets_service():\n",
    "    \"\"\"\n",
    "    OAuth Installed App flow.\n",
    "    - First run opens a browser to consent, saves token.json\n",
    "    - Future runs reuse token.json\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "\n",
    "    if TOKEN_JSON.exists():\n",
    "        creds = Credentials.from_authorized_user_file(str(TOKEN_JSON), SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            if not CREDENTIALS_JSON.exists():\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Missing {CREDENTIALS_JSON}. Save your OAuth JSON as 'credentials.json' next to this script.\"\n",
    "                )\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_JSON), SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        TOKEN_JSON.write_text(creds.to_json(), encoding=\"utf-8\")\n",
    "\n",
    "    return build(\"sheets\", \"v4\", credentials=creds)\n",
    "\n",
    "def ensure_tab(service, spreadsheet_id: str, sheet_name: str):\n",
    "    meta = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()\n",
    "    existing = [s[\"properties\"][\"title\"] for s in meta.get(\"sheets\", [])]\n",
    "    if sheet_name in existing:\n",
    "        return\n",
    "    req = {\"requests\": [{\"addSheet\": {\"properties\": {\"title\": sheet_name}}}]}\n",
    "    service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body=req).execute()\n",
    "\n",
    "def upload_df_to_sheet(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str, mode: str = \"append\"):\n",
    "    if not spreadsheet_id:\n",
    "        raise ValueError(\"SHEET_ID is missing in .env\")\n",
    "    service = get_sheets_service()\n",
    "    ensure_tab(service, spreadsheet_id, sheet_name)\n",
    "\n",
    "    header_and_rows = [df.columns.tolist()] + df.astype(str).values.tolist()\n",
    "\n",
    "    if mode == \"overwrite\":\n",
    "        service.spreadsheets().values().clear(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A:ZZ\",\n",
    "            body={}\n",
    "        ).execute()\n",
    "        service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            body={\"values\": header_and_rows},\n",
    "        ).execute()\n",
    "        print(f\"✅ Uploaded to Google Sheet (overwrite): {sheet_name}\")\n",
    "        return\n",
    "\n",
    "    # append\n",
    "    first_cell = service.spreadsheets().values().get(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        range=f\"{sheet_name}!A1:A1\"\n",
    "    ).execute().get(\"values\", [])\n",
    "\n",
    "    if not first_cell:\n",
    "        service.spreadsheets().values().update(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            body={\"values\": header_and_rows},\n",
    "        ).execute()\n",
    "        print(f\"✅ Uploaded to Google Sheet (new tab): {sheet_name}\")\n",
    "    else:\n",
    "        service.spreadsheets().values().append(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=f\"{sheet_name}!A1\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body={\"values\": df.astype(str).values.tolist()},\n",
    "        ).execute()\n",
    "        print(f\"✅ Appended to Google Sheet: {sheet_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a882fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers: week labels + formatting\n",
    "# -------------------------\n",
    "def format_date_range(start_ymd: str, end_ymd: str) -> str:\n",
    "    sdt = datetime.strptime(start_ymd, \"%Y-%m-%d\")\n",
    "    edt = datetime.strptime(end_ymd, \"%Y-%m-%d\")\n",
    "    return f\"{sdt.month}/{sdt.day}-{edt.month}/{edt.day}\"\n",
    "\n",
    "def month_name_from_date(d: date) -> str:\n",
    "    return d.strftime(\"%B\")\n",
    "\n",
    "def week_start_for(d: date, week_start: int = 0) -> date:\n",
    "    delta = (d.weekday() - week_start) % 7\n",
    "    return d - timedelta(days=delta)\n",
    "\n",
    "def iter_weeks(since: date, until: date, week_start: int = 0):\n",
    "    \"\"\"\n",
    "    Yields (start, end) date pairs inclusive.\n",
    "    Weeks are aligned to week_start (default Monday).\n",
    "    First week starts at since (not earlier), last ends at until.\n",
    "    \"\"\"\n",
    "    cur_start = since\n",
    "    while cur_start <= until:\n",
    "        anchor = week_start_for(cur_start, week_start)\n",
    "        week_end = anchor + timedelta(days=6)\n",
    "        cur_end = min(week_end, until)\n",
    "        yield (cur_start, cur_end)\n",
    "        cur_start = cur_end + timedelta(days=1)\n",
    "\n",
    "def parse_week_labels(raw: str):\n",
    "    \"\"\"\n",
    "    WEEK_LABELS format: \"YYYY-MM-DD:YYYY-MM-DD=Label;YYYY-MM-DD:YYYY-MM-DD=Label2\"\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    if not raw:\n",
    "        return labels\n",
    "    items = [x.strip() for x in raw.split(\";\") if x.strip()]\n",
    "    for item in items:\n",
    "        if \"=\" not in item or \":\" not in item:\n",
    "            continue\n",
    "        k, v = item.split(\"=\", 1)\n",
    "        labels[k.strip()] = v.strip()\n",
    "    return labels\n",
    "\n",
    "WEEK_LABELS = parse_week_labels(WEEK_LABELS_RAW)\n",
    "\n",
    "def get_week_label(start: date, end: date) -> str:\n",
    "    key = f\"{start.isoformat()}:{end.isoformat()}\"\n",
    "    return WEEK_LABELS.get(key, \"\")\n",
    "\n",
    "# -------------------------\n",
    "# Helpers: parsing Shopify export\n",
    "# -------------------------\n",
    "def to_number(x) -> float:\n",
    "    if x is None:\n",
    "        return 0.0\n",
    "    s = str(x).strip()\n",
    "    if s in (\"\", \"—\", \"-\", \"nan\", \"None\"):\n",
    "        return 0.0\n",
    "    s = s.replace(\"$\", \"\").replace(\",\", \"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def bucket_row(ref_platform: str, channel: str, typ: str) -> str:\n",
    "    rp = (ref_platform or \"\").strip().lower()\n",
    "    ch = (channel or \"\").strip().lower()\n",
    "    ty = (typ or \"\").strip().lower()\n",
    "\n",
    "    if ch == \"direct\" or rp == \"direct\":\n",
    "        return \"Direct Website Sales (Organic)\"\n",
    "\n",
    "    if ch == \"google\" and ty == \"paid\":\n",
    "        return \"Google ads (Sales)\"\n",
    "\n",
    "    if ch == \"google\" and ty == \"organic\":\n",
    "        return \"Google Search (Organic Sales)\"\n",
    "\n",
    "    if ch == \"attentive\" or rp == \"attentive\":\n",
    "        return \"Attentive SMS (Sales)\"\n",
    "\n",
    "    if ch == \"privy\" or rp == \"privy\":\n",
    "        return \"Privey Email Marketing (Sales)\"\n",
    "    \n",
    "    if ch == \"activecampaign\" or rp == \"activecampaign\":\n",
    "        return \"ActiveCampaign (Sales)\"\n",
    "\n",
    "    return \"Other Channel Sales MISC\"\n",
    "\n",
    "def build_misc_notes(df_other: pd.DataFrame, channel_col: str, type_col: str, sales_col: str) -> str:\n",
    "    if df_other.empty:\n",
    "        return \"\"\n",
    "    tmp = df_other.copy()\n",
    "    tmp[\"_name\"] = tmp.apply(lambda r: f\"{str(r[channel_col]).strip()} ({str(r[type_col]).strip()})\", axis=1)\n",
    "    tmp[\"_sales\"] = tmp[sales_col].apply(to_number)\n",
    "    grouped = (\n",
    "        tmp.groupby(\"_name\", as_index=False)[\"_sales\"].sum()\n",
    "        .sort_values(\"_sales\", ascending=False)\n",
    "    )\n",
    "    parts = []\n",
    "    for _, r in grouped.head(10).iterrows():\n",
    "        if r[\"_sales\"] > 0:\n",
    "            parts.append(f\"{r['_name']} ${r['_sales']:,.2f}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "def summarize_channel_csv_to_weekly_row(csv_path: Path, start: date, end: date) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    colmap = {c.lower().strip(): c for c in df.columns}\n",
    "    def col(name_lower):\n",
    "        return colmap.get(name_lower, None)\n",
    "\n",
    "    rp_col = col(\"referring platform\")\n",
    "    ch_col = col(\"channel\")\n",
    "    ty_col = col(\"type\")\n",
    "    sales_col = col(\"sales\")\n",
    "    cost_col = col(\"cost\")\n",
    "\n",
    "    if not (rp_col and ch_col and ty_col and sales_col):\n",
    "        raise ValueError(f\"CSV missing required columns. Found: {list(df.columns)}\")\n",
    "\n",
    "    df[\"_sales\"] = df[sales_col].apply(to_number)\n",
    "    df[\"_cost\"] = df[cost_col].apply(to_number) if cost_col else 0.0\n",
    "\n",
    "    df[\"_bucket\"] = df.apply(lambda r: bucket_row(r[rp_col], r[ch_col], r[ty_col]), axis=1)\n",
    "\n",
    "    agg = df.groupby(\"_bucket\", as_index=False).agg({\"_sales\": \"sum\", \"_cost\": \"sum\"})\n",
    "    sales_by = {row[\"_bucket\"]: float(row[\"_sales\"]) for _, row in agg.iterrows()}\n",
    "    cost_by  = {row[\"_bucket\"]: float(row[\"_cost\"])  for _, row in agg.iterrows()}\n",
    "\n",
    "    other_df = df[df[\"_bucket\"] == \"Other Channel Sales MISC\"].copy()\n",
    "    misc_notes = build_misc_notes(other_df, ch_col, ty_col, sales_col)\n",
    "\n",
    "    tot_sales = float(df[\"_sales\"].sum())\n",
    "    tot_cost  = float(df[\"_cost\"].sum())\n",
    "\n",
    "    # Not true gross margin; this is marketing margin proxy\n",
    "    marketing_margin = ((tot_sales - tot_cost) / tot_sales) if tot_sales else 0.0\n",
    "\n",
    "    start_str = start.isoformat()\n",
    "    end_str = end.isoformat()\n",
    "\n",
    "    label = get_week_label(start, end)\n",
    "    dates_week = format_date_range(start_str, end_str)\n",
    "    if label:\n",
    "        dates_week = f\"{dates_week} ({label})\"\n",
    "\n",
    "    month = month_name_from_date(start)\n",
    "\n",
    "    row = {\n",
    "        \"Month\": month,\n",
    "        \"Dates/ Week\": dates_week,\n",
    "\n",
    "        \"Direct Website Sales (Organic)\": round(sales_by.get(\"Direct Website Sales (Organic)\", 0.0), 2),\n",
    "        \"Google ads (Sales)\": round(sales_by.get(\"Google ads (Sales)\", 0.0), 2),\n",
    "        \"Google Search (Organic Sales)\": round(sales_by.get(\"Google Search (Organic Sales)\", 0.0), 2),\n",
    "        \"Attentive SMS (Sales)\": round(sales_by.get(\"Attentive SMS (Sales)\", 0.0), 2),\n",
    "        \"Privey Email Marketing (Sales)\": round(sales_by.get(\"Privey Email Marketing (Sales)\", 0.0), 2),\n",
    "        \"ActiveCampaign (Sales)\": round(sales_by.get(\"ActiveCampaign (Sales)\", 0.0), 2),\n",
    "        \"Other Channel Sales MISC\": round(sales_by.get(\"Other Channel Sales MISC\", 0.0), 2),\n",
    "\n",
    "        \"Tot Sales\": round(tot_sales, 2),\n",
    "\n",
    "        \"Google ads (Cost)\": round(cost_by.get(\"Google ads (Sales)\", 0.0), 2),\n",
    "        \"Privey Email Marketing (Cost)\": round(cost_by.get(\"Privey Email Marketing (Sales)\", 0.0), 2),\n",
    "        \"Attentive SMS (Cost)\": round(cost_by.get(\"Attentive SMS (Sales)\", 0.0), 2),\n",
    "        \"Total Cost\": round(tot_cost, 2),\n",
    "\n",
    "        \"GPM\": round(marketing_margin, 4),\n",
    "        \"MISC.\": misc_notes,\n",
    "\n",
    "        # \"Upload_Date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "        \"Range_Start\": start_str,\n",
    "        \"Range_End\": end_str,\n",
    "        \"Country\": COUNTRY,\n",
    "    }\n",
    "\n",
    "    ordered_cols = [\n",
    "        \"Month\",\n",
    "        \"Dates/ Week\",\n",
    "        \"Direct Website Sales (Organic)\",\n",
    "        \"Google ads (Sales)\",\n",
    "        \"Google Search (Organic Sales)\",\n",
    "        \"Attentive SMS (Sales)\",\n",
    "        \"Privey Email Marketing (Sales)\",\n",
    "        \"ActiveCampaign (Sales)\",\n",
    "        \"Other Channel Sales MISC\",\n",
    "        \"Tot Sales\",\n",
    "        \"Google ads (Cost)\",\n",
    "        \"Privey Email Marketing (Cost)\",\n",
    "        \"Attentive SMS (Cost)\",\n",
    "        \"Total Cost\",\n",
    "        \"GPM\",\n",
    "        \"MISC.\",\n",
    "        # \"Upload_Date\",\n",
    "        \"Range_Start\",\n",
    "        \"Range_End\",\n",
    "        \"Country\",\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame([[row.get(c, \"\") for c in ordered_cols]], columns=ordered_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a12527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Shopify: build URL + click export\n",
    "# -------------------------\n",
    "def build_report_url(store_slug: str, since_ymd: str, until_ymd: str, country: str) -> str:\n",
    "    return (\n",
    "        f\"https://admin.shopify.com/store/{store_slug}/marketing/reports/channels\"\n",
    "        f\"?attributionModel=last_click_non_direct\"\n",
    "        f\"&since={since_ymd}&until={until_ymd}\"\n",
    "        f\"&sortColumn=sessions&sortDirection=desc\"\n",
    "        f\"&country={country}\"\n",
    "    )\n",
    "\n",
    "async def click_export_flow(page):\n",
    "    # Wait until the page is interactive\n",
    "    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "    await page.wait_for_timeout(1200)\n",
    "\n",
    "    # Sometimes the report UI takes extra time\n",
    "    # Wait for any button area to render\n",
    "    await page.wait_for_selector(\"button\", timeout=60000)\n",
    "\n",
    "    # 1) Try direct Export button (several variants)\n",
    "    export_clicked = False\n",
    "    export_selectors = [\n",
    "        \"button:has-text('Export')\",\n",
    "        \"button[aria-label='Export']\",\n",
    "        \"[role='button']:has-text('Export')\",\n",
    "    ]\n",
    "    for sel in export_selectors:\n",
    "        try:\n",
    "            await page.click(sel, timeout=5000)\n",
    "            export_clicked = True\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) If not found, try overflow menu then Export\n",
    "    if not export_clicked:\n",
    "        overflow_selectors = [\n",
    "            \"button[aria-label='More actions']\",\n",
    "            \"button[aria-haspopup='menu']\",\n",
    "            \"button:has-text('More actions')\",\n",
    "            \"button:has-text('More')\",\n",
    "        ]\n",
    "        for sel in overflow_selectors:\n",
    "            try:\n",
    "                await page.click(sel, timeout=5000)\n",
    "                break\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # click Export inside menu\n",
    "        await page.click(\"text=Export\", timeout=15000)\n",
    "\n",
    "    await page.wait_for_timeout(800)\n",
    "\n",
    "    # 3) Choose CSV if there is a choice\n",
    "    csv_selectors = [\n",
    "        \"text=CSV\",\n",
    "        \"button:has-text('CSV')\",\n",
    "        \"[role='menuitem']:has-text('CSV')\",\n",
    "        \"label:has-text('CSV')\",\n",
    "    ]\n",
    "    for sel in csv_selectors:\n",
    "        try:\n",
    "            await page.click(sel, timeout=2500)\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 4) Confirm Export (dialog)\n",
    "    confirm_selectors = [\n",
    "        \"button:has-text('Export')\",\n",
    "        \"button[aria-label='Export']\",\n",
    "        \"text=Export\",\n",
    "    ]\n",
    "    for sel in confirm_selectors:\n",
    "        try:\n",
    "            await page.click(sel, timeout=8000)\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "async def auto_login_shopify(page):\n",
    "    \"\"\"\n",
    "    Attempt Shopify login using SHOPIFY_EMAIL/SHOPIFY_PASSWORD from .env.\n",
    "    If 2FA prompt appears, asks for code (or uses SHOPIFY_OTP if provided).\n",
    "    \"\"\"\n",
    "    if not SHOPIFY_EMAIL or not SHOPIFY_PASSWORD:\n",
    "        raise ValueError(\"AUTO_LOGIN=1 but SHOPIFY_EMAIL/SHOPIFY_PASSWORD missing in .env\")\n",
    "\n",
    "    await page.goto(f\"https://admin.shopify.com/store/{STORE_SLUG}\", timeout=60000)\n",
    "    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "\n",
    "    # Email step\n",
    "    try:\n",
    "        await page.fill(\"#account_email\", SHOPIFY_EMAIL, timeout=15000)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Password step\n",
    "    try:\n",
    "        await page.fill(\"#account_password\", SHOPIFY_PASSWORD, timeout=15000)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2FA step (if present)\n",
    "    try:\n",
    "        otp_selector = \"input[name='two_factor_code'], input[name='otp']\"\n",
    "        await page.wait_for_selector(otp_selector, timeout=8000)\n",
    "        otp = os.getenv(\"SHOPIFY_OTP\", \"\").strip() or input(\"Enter Shopify 2FA code: \").strip()\n",
    "        await page.fill(otp_selector, otp)\n",
    "        await page.click(\"button[name='commit']\", timeout=15000)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Wait for admin UI\n",
    "    await page.wait_for_selector(\"nav[aria-label='Primary'], #AppFrameMain\", timeout=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418756b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Main automation\n",
    "# -------------------------\n",
    "async def run():\n",
    "    if not STORE_SLUG:\n",
    "        raise ValueError(\"Missing SHOPIFY_STORE_SLUG in .env\")\n",
    "\n",
    "    since_d = parse_ymd(SINCE)\n",
    "    until_d = parse_ymd(UNTIL)\n",
    "    if until_d < since_d:\n",
    "        raise ValueError(\"UNTIL must be >= SINCE\")\n",
    "\n",
    "    print(f\"DOWNLOAD_DIR: {DOWNLOAD_DIR}\")\n",
    "    print(f\"Range: {since_d} -> {until_d} (inclusive)\")\n",
    "    print(f\"Weekly loop (week_start={WEEK_START}, Mon=0)\")\n",
    "    print(f\"UPLOAD_TO_SHEET={UPLOAD_TO_SHEET} SHEET_MODE={SHEET_MODE}\")\n",
    "\n",
    "    overwrite_first = (SHEET_MODE == \"overwrite\")\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=HEADLESS,\n",
    "            args=[\"--disable-dev-shm-usage\", \"--no-sandbox\", \"--disable-setuid-sandbox\"]\n",
    "        )\n",
    "\n",
    "        if STATE_FILE.exists():\n",
    "            context = await browser.new_context(storage_state=str(STATE_FILE), accept_downloads=True)\n",
    "        else:\n",
    "            context = await browser.new_context(accept_downloads=True)\n",
    "\n",
    "        page = await context.new_page()\n",
    "\n",
    "        try:\n",
    "            await page.goto(f\"https://admin.shopify.com/store/{STORE_SLUG}\", timeout=60000)\n",
    "\n",
    "            if not STATE_FILE.exists():\n",
    "                if AUTO_LOGIN:\n",
    "                    print(\"\\nAUTO_LOGIN enabled: attempting Shopify login...\")\n",
    "                    await auto_login_shopify(page)\n",
    "                else:\n",
    "                    print(\"\\n✅ FIRST RUN: Log into Shopify in the opened browser window.\")\n",
    "                    print(\"   When Shopify Admin is fully loaded, return here and press Enter.\\n\")\n",
    "                    input(\"Press Enter after Shopify login is complete... \")\n",
    "\n",
    "                await context.storage_state(path=str(STATE_FILE))\n",
    "                print(f\"✅ Saved Shopify session to: {STATE_FILE}\\n\")\n",
    "\n",
    "            all_summary_rows = []\n",
    "\n",
    "            for start, end in iter_weeks(since_d, until_d, week_start=WEEK_START):\n",
    "                since_ymd = start.isoformat()\n",
    "                until_ymd = end.isoformat()\n",
    "                report_url = build_report_url(STORE_SLUG, since_ymd, until_ymd, COUNTRY)\n",
    "\n",
    "                print(f\"\\n--- Exporting {since_ymd} to {until_ymd} ---\")\n",
    "                await page.goto(report_url, timeout=60000)\n",
    "\n",
    "                async with page.expect_download(timeout=180000) as dl_info:\n",
    "                    await click_export_flow(page)\n",
    "                download = await dl_info.value\n",
    "\n",
    "                stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                dest = DOWNLOAD_DIR / f\"shopify_channel_perf_{COUNTRY}_{since_ymd}_{until_ymd}_{stamp}.csv\"\n",
    "                await download.save_as(str(dest))\n",
    "                print(f\"✅ Downloaded: {dest}\")\n",
    "\n",
    "                summary_df = summarize_channel_csv_to_weekly_row(dest, start, end)\n",
    "                all_summary_rows.append(summary_df)\n",
    "\n",
    "                summary_path = dest.with_name(dest.stem + \"_SUMMARY.csv\")\n",
    "                summary_df.to_csv(summary_path, index=False)\n",
    "                print(f\"✅ Summary saved: {summary_path}\")\n",
    "\n",
    "                if UPLOAD_TO_SHEET:\n",
    "                    mode = \"overwrite\" if overwrite_first else \"append\"\n",
    "                    upload_df_to_sheet(summary_df, SHEET_ID, SHEET_NAME, mode=mode)\n",
    "                    overwrite_first = False\n",
    "\n",
    "            if all_summary_rows:\n",
    "                combined = pd.concat(all_summary_rows, ignore_index=True)\n",
    "                combined_path = DOWNLOAD_DIR / f\"shopify_weekly_summary_{COUNTRY}_{SINCE}_{UNTIL}_{time.strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                combined.to_csv(combined_path, index=False)\n",
    "                print(f\"\\n✅ Combined summary saved: {combined_path}\")\n",
    "\n",
    "        finally:\n",
    "            await context.close()\n",
    "            await browser.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df039a50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
